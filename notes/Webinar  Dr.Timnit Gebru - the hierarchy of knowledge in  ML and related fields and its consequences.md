### Webinar Dr.Timnit Gebru
 Dr. Timnit Gebru speaks about the hierarchy if knowledge in ML and it's consequences on 14th of April 6pm (Berlin time) (edited) 

[The Hierarchy of Knowledge in Machine Learning and Related Fields and Its Consequences](https://www.spelman.edu/coe-mws/news-events/the-future-is-intersectional-series/2021/04/14/default-calendar/the-hierarchy-of-knowledge-in-machine-learning-and-related-fields-and-its-consequences)

### Notes and Ressources

Prof. Ruha Benjamin "Reimagining the Default Settings of Technology and Society"
https://iclr.cc/virtual_2020/speaker_3.html

MIT's moralizing: 
https://docs.google.com/forms/d/e/1FAIpQLSfzPVBhrulpTJjAU2Rl36sFA1TJR4_uet4sktPOS3Fdxmqi8w/viewform

>"Great point about the importance of a whole person being worthy of ACM’s highest awards."

>"View from nowhere" --> important concept which still gets ignored on a large scale

Replacing the ‘View from Nowhere’: A Pragmatist-Feminist Science Classroom:
https://scholars.unh.edu/educ_facpub/44/

>"Cant separate the institution from its history, just as you can’t separate the problematic views of a person from their professional work" --> there has to be a line, indeed (see T.)

>Dr. Gebru often is described as an activist "activist" instead of "scientists" --> usually she hears this only with a negative connotation "activist " --> label to categorize and target people

"Carl Sagan Effect":  https://www.thehindu.com/opinion/op-ed/what-is-sagan-effect-in-science/article19589191.ece

> Ideas from game theory willingly get incorporated into ml developement but why not ideas of history

"Programmed inequality" https://mitpress.mit.edu/books/programmed-inequality

> "Gatekeeping is always done by those in power"

> Dr. Gebru brings ideas outside of her dicipline into her discipline

El Mahdi El Mhamdi - https://twitter.com/L_badikho

Interview with Sabelo Mhlambi: https://medium.com/people-ai-research/q-a-sabelo-mhlambi-on-what-ai-can-learn-from-ubuntu-ethics-4012a53ec2a6


Data Sheets for Datasets, disaggregited testing
Datasheets for Datasets: https://arxiv.org/abs/1803.09010

Model Cards for Model Reporting https://arxiv.org/abs/1810.03993

Project on which Dr. Gebru worked while being at Google:
Model Cards with Google: 
https://modelcards.withgoogle.com


> ML is all about categorizing. A lot about information collection and organization can be learned from the librarian sciences.


"Algorithms of opression" Libray sciences
Lessons from Archives: Strategies for Collecting Sociocultural Data in Machine Learning https://arxiv.org/abs/1912.10389


Kimberle Crenshaw - Intersectionality - https://chicagounbound.uchicago.edu/cgi/viewcontent.cgi?article=1052&context=uclf

Diversity and Inclusion Metrics in Subset Selection https://arxiv.org/abs/2002.03256

Amazon is Pushing for Facial Technology: https://www.nytimes.com/2019/01/24/technology/amazon-facial-technology-study.html


Search results that reflect historic inequities can amplify stereotypes and perpetuate under-representation. Carefully measuring diversity can help:
https://twitter.com/erikashimizu/status/1372236358136238080?s=20 
explorable: https://pair.withgoogle.com/explorables/measuring-diversity
colab: https://colab.research.google.com/github/PAIR-co

playbook abuse and misogyny: https://www.media.mit.edu/publications/abuse-and-misogynoir-playbook/


Black in AI is a place for sharing ideas, fostering collaborations and discussing initiatives to increase the presence of Black people in the field of Artificial Intelligence: https://blackinai.org

> "Coded Bias" Documentary was also reccomended

Algorithmic Justice League - https://www.ajl.org/


Data Feminism book mentioned earlier (open access, free to read) - https://data-feminism.mitpress.mit.edu/

Joy Buolamwini: "AI, Ain't I A Woman?" (2018) https://www.blackhistory.mit.edu/archive/joy-buolamwini-ai-aint-i-woman-2018


Coded Bias - https://www.codedbias.com/

Ghost Work: https://ghostwork.info/

Critical Perspectives on Computer Vision: https://slideslive.com/38923500/critical-perspectives-on-computer-vision

Large image datasets: A pyrrhic win for computer vision? https://arxiv.org/abs/2006.16923

Bias deep inside the code: https://www.theguardian.com/technology/2019/mar/28/big-tech-ai-ethics-boards-prejudice

Gender Recognition or Gender Reduction: https://dl.acm.org/doi/10.1145/3173574.3173582

>Word Bias is a bit distracting (also passive)
---> instead lets talk about power (very active)

### Organizational Details

Mailing List: http://eepurl.com/huwBh1

Ressources and recording:
https://www.spelman.edu/coe-mws/news-events/the-future-is-intersectional-series